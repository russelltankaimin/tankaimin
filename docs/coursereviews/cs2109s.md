---
layout: default
title: CS2109S
parent: "Course Reviews"
nav_order: 19
has_children: false
---

# Introduction to Artificial Intelligence and Machine Learning
*Academic Year 2022 - 2023*  
*Semester 2*

# NUSMods Description
> This course introduces basic concepts in Artificial Intelligence (AI) and Machine Learning (ML). It adopts the perspective that planning, games, and learning are related types of search problems, and examines the underlying issues, challenges and techniques. Planning/games related topics include tree/graph search, A* search, local search, and adversarial search (e.g., games). Learning related topics include supervised and unsupervised learning, model validation, and neural networks.

# Review
This module is taught by Prof Ben Leong (yes the infamous one). It has a 2hr lecture and 1hr tutorial per week.

There are around 8 Psets, 1 Midterm and a Final and a Mini Project. The Psets are quite easy. Usually it is done within a day or 2. As for the midterm, I was actually pretty confident since algorithms are my strong point, and I also enjoyed CS2040S and CS3230 a lot and scored a good grade. However, time was very tight. The decision tree question had the most convoluted way of shading. TBH I think the prof is better off using "visual input" to mark our decision trees as opposed to making us shade. That cost me a lot of time which made me forgo a 28 mark qns. I got full marks for the classical AI question. Eventually scored slightly above median.

For the mini-project, we had to use alpha-beta pruning to play Breakthrough. We had to minimally beat the hidden baby and base agent, and then your final score was based on the competition round. AKA how many people can you beat. I scored below median for this with a rank of 170 out of 250(?). This project ate up a lot of my time, but I managed to beat baby and base agent with only 3 levels whilst in isolation (I got Covid at that time).

The final project was a 28hr Kaggle Contest held on Saturday (Hari Raya Puasa night at 8 pm). Basically, we were given a dataset with labels V0 .... V60 and some images too. I had already had some templates built beforehand from the mock, so I managed to get a working model around 2 hours in(?). However, this was the most stressful 28hrs ever because there was a live scoreboard. When you think you scored a good enough metric, a few hours later, you are probably at the bottom few already. I had to repeatedly do Hyperparameter tunings and random seeding. At around 11 pm on Sunday, I gave up and just submitted my code and report. I eventually scored 85/100 with a 56th percentile performance in the performance metric of my model on the hidden dataset.

Lectures were not very useful -- except when the other Prof taught Principal Component Analysis. I remembered I had COVID then so I had to watch the recording instead. Despite that, I think the other prof was really articulate and engaging about ML. I think the main Prof dumbed down a lot of the math necessary for ML because he was scared (?) we suck at math, not sure if it was a compromise. I stopped going to lectures straight after midterms. I studied the content myself and watched Youtube videos, and read books and articles online instead. My tutor for tutorials is very knowledgeable and well-prepared. He is the same year as me, and he is very articulate. I really appreciated it. I think I learnt more from him than the actual lectures.


